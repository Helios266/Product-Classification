{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$========= Mini-project: Product \\ Recognizer =========$$\n",
    "\n",
    "$$H.Cuong,\\ P.Duan.\\ Global \\ cybersoft \\ - \\ Hitachi \\ Consulting \\ Viet \\ Nam$$\n",
    "$$cuongthh@hitachiconsulting.com,\\ duanvp@hitachiconsulting.com$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#introduction) <br>\n",
    "2. [Related work ](#paragraph1)<br>\n",
    "    2.1. [Image processing](#subparagraph21)<br>\n",
    "    2.2. [Neural network](#subparagraph22)<br>\n",
    "    2.3. [Python](#subparagraph23)<br>\n",
    "    2.4. [Web app](#subparagraph24)<br>\n",
    "3. [Project requirement](#paragraph2)<br>\n",
    "    3.1. [Overall](#subparagraph31)<br>\n",
    "    3.2. [Input](#subparagraph32)<br>\n",
    "    3.3. [Output](#subparagraph33)<br>\n",
    "4. [Our proposal](#paragraph3)<br>\n",
    "    4.1. [Data preparation](#subparagraph41)<br>\n",
    "    4.2. [Model](#subparagraph42)<br>\n",
    "    4.3. [Evalution](#subparagraph43)<br>\n",
    "    4.4. [Web application](#subparagraph44)<br>\n",
    "5. [Our estimate](#paragraph4)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction <a name=\"introduction\"></a>\n",
    "<pre>\n",
    "</pre> \n",
    "   Ngày nay, ngành bán lẻ đòi hỏi một lượng lớn lao động của con người và một tỷ lệ lớn khối lượng công việc được dành cho việc nhận dạng và phân loại sản phẩm để thanh toán. Với sự phát triển gần đây của computer vision, ngày càng đòi hỏi phải sử dụng các công nghệ nhận dạng hình ảnh để tự động hóa nhận dạng sản phẩm. Từ góc độ là những người mới trong lĩnh vực, đây là đề tài khá thú vị để nghiên cứu vì vậy chúng tôi muốn thực hiện một mini project: \"Product Recognition\" liên quan đến nhận dạng sản phẩm.<br> <br>\n",
    "    Việc nhận dạng sản phẩm là một vấn đề phân loại rất khó khăn vì nhiều lớp sản phẩm giống nhau về hình dạng, màu sắc, kết cấu và kích thước số liệu. Bởi vậy chúng tôi tiến hành dự án nhỏ \"Product Recognition\" phân loại các sản phẩm trên tập dataset gồm hình ảnh 200 loại sản phẩm khác nhau (200 class), mỗi sản phẩm được chụp bởi nhiều góc độ, trong một môi trường được kiểm soát. Dự án này sẽ là nền tảng, cơ sở bước đầu để nghiên cứu, thực hiện một dự án lớn hơn về việc nhận dạng sản phẩm có tính ứng dụng cao sau này.<br> \n",
    "<img src=\"supervision.jpg\"  alt=\" Alt text that describes the graphic \" title=\"Figure 1: Product Recognition [3]\" />\n",
    "$$Figure \\ 1: Product \\ Recognition [1]$$\n",
    "<pre></pre>\n",
    "Với dự án \"Product Recognition\", chúng tôi xây dựng một mô hình neural network được viết bởi ngôn ngữ lập trình python. Python là một ngôn ngữ lập trình dễ dàng để tiếp cận, cú pháp lệnh của Python là điểm cộng vô cùng lớn vì sự rõ ràng, dễ hiểu và cách gõ linh động làm cho nó nhanh chóng trở thành một ngôn ngữ lý tưởng để viết script và phát triển ứng dụng trong nhiều lĩnh vực, ở hầu hết các nền tảng. Khi viết bằng ngôn ngữ lập trình python việc cài đặt một số thư viên quan trọng là điều thiết yếu, ví như:\n",
    "<br> -NumPy: đây là một thư viện cho ngôn ngữ lập trình Python, thêm hỗ trợ cho các mảng và ma trận lớn, đa chiều, cùng với một tập hợp lớn các hàm toán học cấp cao để hoạt động trên các mảng này. \n",
    " <br> -Scipy: là thư viện chứa các module để tối ưu hóa, đại số tuyến tính, tích hợp, nội suy, các chức năng đặc biệt, xử lý tín hiệu và hình ảnh và các nhiệm vụ phổ biến khác trong khoa học và kỹ thuật.\n",
    "  <br> -Matplotlib: đây là thư viện dùng cho việc vẽ đồ thị trên python.\n",
    "  <br> -OpenCV2 (Open source computer vision): một thư viện mã nguồn mở hàng đầu cho thị giác máy tính (computer vision).<br><br>\n",
    "Sau khi có được mô hình chất lượng thì chúng tôi tạo web app bằng framework Flask và JavaScript để chia sẻ model. Flask là một micro web framework viết bởi python, Flask hỗ trợ các tiện ích mở rộng và chúng được cập nhật thường xuyên và nó có kiến trúc nhỏ, gọn nên bạn hoàn toàn không bị bó buộc bởi bộ khung cồng kềnh, không gặp bất cứ khó khăn nào khi cấu hình hay tổ chức ứng dụng. Ngoài ra, Flask còn cực kỳ linh hoạt, tối giản dễ tìm hiểu và sử dụng.<br> <br>\n",
    "Phần tiếp theo, chúng tôi sẽ trình bày chi tiết hướng đi và phương pháp xây dựng mô hình neural network, quá trình huấn luyện mô hình rồi báo cáo và phân tích kết quả. Cuối cùng là chỉ ra những điều đã đạt được, chưa đạt được trong quá trình làm dự án và đề cập hướng phát triển tiếp theo cho dự án.\n",
    "### 2. Related work  <a name=\"paragraph1\"></a>\n",
    "<pre></pre>\n",
    "#### 2.1 Image processing (Xử lý ảnh): <a name=\"subparagraph21\"></a>\n",
    "Xử lý ảnh thực chất là thực hiện các phép toán trên từng pixel của ảnh nhằm giải quyết các bài toán như:<br>\n",
    "-Đo lường đối tượng: Xác định vết nứt trên tường dựa vào ảnh chụp từ camera, đo lường kích cỡ chân IC, đo lường khoảng cách từ đối tượng đến camera,...<br>\n",
    "-Bám đối tượng: Sử dụng máy bay không người lái để bám theo một mục tiêu nào đấy, sử dụng camera để giám sát cảnh báo lái xe ngủ gật,...<br>\n",
    "-Nhận dạng: Nhận dạng biển số xe, nhận dạng khuôn mặt người, nhận dạng vân tay, nhận dạng chữ viết,...<br>\n",
    "-Phân loại: Phân loại sản phẩm theo màu sắc, kích cỡ, đánh giá chất lượng nông sản,...<br>\n",
    "-Xây dựng phần mềm xử lý ảnh chuyên nghiệp như photoshop, camera360,...<br>\n",
    "Ứng dụng xử lý ảnh hiện nay vô cùng phong phú, đã có một ngành khoa học nghiên cứu về nó chính là Computer Vision. Một số tác phẩm kinh điển về xử lý ảnh:[2][3][4].<br>\n",
    "Với tập dataset gồm gần 54.000 ảnh màu của 200 loại sản phẩm, mỗi ảnh có kích thước 224x224x3. Để đơn giản cho việc thử nghiệm mô hình neural network, chúng tôi tiến hành image processing: xóa background của từng sản phẩm rồi thay thế bằng màu gray và giữ nguyên kích thước ảnh.\n",
    "<img src=\"6909409012031-back_camera1-19.jpg\"/>\n",
    "$$Figure \\ 2: Ví \\ dụ \\ của \\ một \\ mẫu \\ sau \\ khi \\ image \\ processing $$\n",
    "Sau đó đưa tất cả ảnh màu về ảnh xám với kích thước 224x224 sau đó resize ảnh về kích thước nhỏ hơn. Load tất cả các ảnh chuyển về mảng X=(N, size x size) với N là số lượng mẫu ảnh, và mảng y=(M,1) với M là số loại sản phẩm (label). <br>\n",
    "#### 2.2 Neural Network: <a name=\"subparagraph22\"></a>\n",
    "Neural network là một mô hình toán học hay mô hình tính toán được xây dựng dựa trên các mạng neural sinh học. Trong những năm thập niên 80, 90, với sự ra đời của Artificial neural networks (ANN) và được sử dụng rất nhiều cho đến cuối những năm 90 khi mà ANN không còn khả thi nữa do giới hạn về phần cứng máy tính. ANN gồm 3 thành phần chính: Input layer, hidden layer và output layer. Input layer và output layer chỉ có 1 lớp, hidden layer có 1 hay nhiều lớp tùy thuộc vào bài toán cụ thể. Mỗi hidden layer được tạo bởi một tập các neural (mỗi neural trong layer được connect với toàn bộ các neural của layer liền trước nó), và điểm đặc biệt là các neural thuộc cùng một layer hoạt động hoàn toàn biệt lập với nhau.\n",
    "<img src=\"5fc47b38-52fb-4701-8c78-180982a9cdb5.jpeg\"/>\n",
    "$$Figure \\ 3: Mô \\ hình \\ neural \\ network.[5]$$\n",
    "Cùng với sự phát triển của machine learning, ngày càng có nhiều đề tài, nhiều cuộc nghiên cứu, thử nghiệm liên quan về neural network, và theo đấy thì có nhiều mô hình neural network được tạo ra bằng nhiều phương pháp, nhiều hướng đi với nhiều mục đích khác nhau. Một trong số đấy là những mô hình neural network huấn luyện trên tập MNIST[6] như: Nonlinear NCA[7]. Nhưng bên cạnh đó performance của mạng NN truyền thống cũng không tốt với vấn đề xử lý ảnh. Chẳng hạn với một bức ảnh có kích thước nhỏ: 32x32x3 (width = 32, height = 32, color channels = 3 – Red Green Blue) thì số lượng feature của input sẽ là 32x32x3 = 3072 dẫn đến ở hidden layer đầu tiên, ngay sau input layer mỗi neural sẽ phải có lượng trọng số (weights) là 3072, vẫn kiểm soát được, tuy nhiên nếu với ảnh lớn hơn một chút chỉ vào khoảng 200x200x3 thì mỗi neural đã cần tới 120,000 weights.<br>\n",
    "Chính vì vậy nên khi sử dụng mạng NN truyền thống trong xử lý ảnh, kích cỡ của ảnh khiến cho số lượng tham số (trọng số) được sử dụng trong mạng tăng lên chóng mặt và khi số lượng trọng số lớn sẽ khiến chi phí tính toán lớn và dễ dẫn đến overfitting. Khi ta nhìn vào một bức ảnh, bản thân các chi tiết trong ảnh giúp ta định hình được nội dung trong bức ảnh, nhưng nếu ta nhận được từng chi tiết riêng lẻ, và phải hình dung toàn bộ nội dung bức ảnh thì công việc trở nên khó khăn hơn. Vấn đề các neural trên cùng 1 layer hoạt động độc lập với nhau hay chính là việc không sử dụng chung các trọng số khiến cho việc trích xuất nhalg đặc trưng trên input cũng gặp khó khăn hơn dẫn đến yêu cầu nhiều neuron hơn, nhiều layer hơn lúc đấy chi phí tính toán tăng và dễ vướng vào overfitting.<br>\n",
    "Vì vậy các mạng NN mới liên tiếp ra đời, cố gắng giải quyết vấn đề này. Cụ thể trong các mạng NN mới trọng số được dùng chung giữa các neural theo nhiều cách, giúp giảm số lượng trọng số, giảm chi phí tính toán, nhưng vẫn đem lại kết quả tốt. Điển hình trong số đó là Convolution Neural Network (CNN), cũng giống như mạng NN truyền thống CNN hoạt động theo phương thức nhận input và biến đổi input thông qua các layer, tuy nhiên điểm khác biệt nằm ở cấu trúc của input và cấu trúc bên trong 1 layer.<br>\n",
    "Input lấy cảm hứng từ xử lý ảnh nên input của CNN có dạng như một bức ảnh chứ không có dạng vector như ANN, cụ thể một bức ảnh sau khi số hoá có dạng width x height x depth (width: số lượng điểm ảnh trên chiều rộng, height: số lượng điểm ảnh trên chiều cao, depth: số lượng kênh chẳng hạn như RGB có 3 kênh đại diện cho mức độ của 3 màu Đỏ, Lục, Lam) nên input của CNN là 1 tensor 3 chiều. Layer ngoài sử dụng layer fully-connected CNN còn sử dụng một số layer đặc biệt như “Convolution Layer” - đây chính là nơi mà các trọng số được share, “ReLU” , “Pool” - không chứa trọng số hay tham số nhưng lại giúp giảm kích thước của ảnh.<br>\n",
    "Sau đây là 2 model CNN mà chúng tôi muốn giới thiệu:\n",
    "* LeNet: Đây là mô hình được phát triển bởi Yann LeCunn (Director of AI Research Facebook) cùng với Léon Bottou, Yoshua Bengio (đồng tác giả với Ian Goodfellow của cuốn “Deep Learning”) và Patrick Haffner.\n",
    "<img src=\"LeNet-5.png\" />\n",
    "$$Figure \\ 5: Mô \\ hình \\ LeNet-5.[8]$$\n",
    "\n",
    "Input: Đầu vào của mô hình là ảnh với kích thước 32x32x1, nghĩa là chiều dài ảnh = 32 pixel, chiều rộng ảnh = 32 pixel và số lượng kênh ảnh là 1 (ảnh đen trắng).<br>\n",
    "Output 10:<br>\n",
    "Output layer có 10 unit, mỗi unit đại diện cho 1 hàm RBF (Euclidean Radial Basis Function) RBF được tính như sau: <br>\n",
    "$$ y _{i} = \\sum _{j} (x _{j} - w _{ij}) ^{2} $$<br>\n",
    "* AlexNet: Đây là mô hình được phát triển bởi Alex Krizhevsky, Ilya Sutskever và Geoffrey E. Hinton - được mệnh danh là God father của Deep Learning. Vào năm 2012, AlexNet được coi là mô hình cho kết quả tốt nhất trong việc phân loại ảnh - cụ thể trong bài báo này viết về kết quả thu được trên tập dữ liệu con của ImageNet (phân loại 1000 class với 1.2 triệu tấm ảnh chất lượng cao). Kết quả thu được như sau: (trên tập test) Top 1 error: 37.5 % Top 5 error: 17.0 % Mô hình này có tới 60 triệu tham số và khoảng 650.000 neurons. Trong đó bao gồm 5 lớp convolution, 3 lớp fully-connected và cuối cùng là softmax với 1000 output.\n",
    "<img src=\"alex.png\" />\n",
    "$$Figure \\ 6: Mô \\ hình \\ AlexNet.[9]$$\n",
    "Kiến trúc của AlexNet:<br>\n",
    "Input Layer: 224 x 224 x 3<br>\n",
    "Output Layer: 1000<br>\n",
    "Thay vì dùng các hàm activation như sigmoid hay tanh, AlexNet đã bắt đầu sử dụng hàm ReLU nhằm giúp tăng tốc độ training để tránh được vanishing gradient và tránh phải rủi ro tràn số (tanh và sigmoid đều sử dụng ex nên dễ bị xấp xỉ = 0 hoặc tràn số khi x quá lớn hoặc quá nhỏ). Về GPU thì do vấn đề về giới hạn bộ nhớ của GPU nên với một GPU độ phức tạp của mạng sẽ bị giới hạn. Nên để AlexNet với kiến trúc như trên thì cần tới 2 GPU để train. Các phần mạng được train trên các GPU khác nhau cũng sẽ chỉ giao tiếp với nhau ở một số lớp nhất định như trên hình và giải thích trong phần kiến trúc mạng.<br>\n",
    "LRN (Local Response Normalization): Để ý rằng với mỗi filter khi áp vào input cho kết quả là 1 channel của output, và các channel này không có mối ràng buộc mất thiết nào với nhau (ngoại trừ việc chung input trước khi tính tích chập) hay thứ tự của các channel trên output là không quan trọng (khi chưa xét đến các layer tiếp theo). Trong trường hợp của AlexNet, sau khi qua activation ReLU, mỗi neuron sau khi tính tích chập được normalize dựa trên những neuron lân cận nó. Cụ thể công thức normalize như sau:<br>\n",
    "$$b ^{i} _{x,y} = \\frac{a ^{i} _{x,y}} {(k + alpha \\sum^{min(N-1,i+\\frac{n}{2})}_{j=max(0,i-\\frac{n}{2})} (a^{i}_{x,y})^{2})^\\beta}[1]$$<br>\n",
    "<b>Trong đó:</b><br>\n",
    "n: số output lân cận - đây là một hyper param <br>\n",
    "N: số lượng filter của layer này<br>\n",
    "$a^i_{x,y}$: là neuron output ở vị trí $x,y)$ sau khi áp filter thứ $i$ $k$,$α$,$β$: là các hyper param để điều chỉnh quá trình normalize này.<br>\n",
    "Overlapping Pooling: Pooling layer của CNN được định nghĩa bởi window size và tốc độ stride. Trong trường hợp window size = stride, các output của các window sẽ độc lập lẫn nhau, khi đó pooling mang ý nghĩa của việc giảm chiều dữ liệu là chính. Nhưng khi window size > stride, các output của các window sẽ có ràng buộc lẫn nhau bởi các window bị overlap. Việc này giúp cho model tránh được phần nào overfitting, trong bài báo có viết, việc sử dựng window size = 3 và stride = 2 giúp cải thiện sai số khoảng 0.3% - 0.4% khi so với việc sử dụng window size = 2 và stride = 2.<br>\n",
    "Đối với dự án \"Product Recognition\" chúng tôi chọn mô hình neural network phù hợp đã có sẵn để training tập dataset(X,y). Khi đã có được kết quả thì chúng tôi sẽ cải thiện, nâng cao hiệu suất của mô hình để tạo được một neural network model chất lượng nhất có thể.<br>\n",
    "\n",
    "#### 2.3 Python:<a name=\"subparagraph23\"></a>\n",
    "Python là một ngôn ngữ lập trình bậc cao cho các mục đích lập trình đa năng, do Guido van Rossum tạo ra và lần đầu ra mắt vào năm 1991. Python được thiết kế với ưu điểm mạnh là dễ đọc, dễ học và dễ nhớ. Python là ngôn ngữ có hình thức sáng sủa, cấu trúc rõ ràng, thuận tiện cho người mới học lập trình. Ban đầu Python được phát triển chạy trên nền Unix. Nhưng rồi theo thời gian, nó đã bành trướng sang mọi hệ điều hành từ MS-DOS đến Mac OS, OS/2, Windows, Linux và các hệ điều hành khác thuộc họ Unix. Mặc dù sự phát triển của Python có sự đóng góp của rất nhiều cá nhân, nhưng Guido van Rossum vẫn là tác giả chủ yếu của Python. Ông giữ vai trò chủ chốt trong việc quyết định hướng phát triển của Python. Vào tháng 7 năm 2008, Van Rossum đã từ chức Leader trong cộng đồng ngôn ngữ Python sau 30 năm lãnh đạo.[10][11]\n",
    "<img src=\"290px-Guido-portrait-2014-curvves.jpg\"/>\n",
    "$$Figure \\ 7: Guido \\ van \\ Rossum \\ at \\ the \\ Dropbox \\ headquarters \\ in \\ 2014.[12]$$\n",
    "Trong quá trình xử lý và xây dựng mô hình neural network tất cả đều được viết bằng ngôn ngữ lập trình python.<br>\n",
    "#### 2.4 Web app (web application):  <a name=\"subparagraph24\"></a>\n",
    "Web app là một trình ứng dụng mà có thể tiếp cận qua web thông qua mạng như Internet. Một ứng dụng Web thông thường được cấu trúc như một ứng dụng ba lớp. Ở dạng phổ biến nhất, một trình duyệt Web là lớp thứ nhất, một bộ máy sử dụng một vài công nghệ nội dung Web động (như ASP, CGI, ColdFusion, JSP/Java, PHP, Python, hoặc Ruby On Rails) là lớp giữa, và một cơ sở dữ liệu là lớp thứ ba. Đối với dự án này thì chúng tôi sử dụng framework Flask để tạo web app. Flask được tạo ra bởi Armin Ronacher của Pocoo, một nhóm những người đam mê Python quốc tế được thành lập vào năm 2004. [13] Theo Ronacher, ý tưởng ban đầu chỉ là một trò đùa Cá tháng Tư đủ phổ biến để biến thành một ứng dụng nghiêm túc. [14] [15] [16]<br>\n",
    "\n",
    "### 3. Project requirement: <a name=\"paragraph2\"></a>\n",
    "#### 3.1 Overall: <a name=\"subparagraph31\"></a>\n",
    "Sau đây là sơ đồ tổng quan về dự án:\n",
    "<img src=\"Overview1.png\" />\n",
    "$$ Figure \\ 8: Overview  \\ of \\ project.$$\n",
    "\n",
    "<img src=\"OverviewANN.png\" />\n",
    "$$ Figure \\ 9: Overview  \\ of \\ Neural \\ Network.$$\n",
    "<p>Chúng tôi sử dụng mô hình Neural Network viết bằng ngôn ngữ Python để học những đặc trưng của từng sản phẩm trong tập dataset, khi mô hình đã được huấn luận xong thì sẽ được lưu trên server của một Web app - được tạo thành bởi framework Flask và cũng viết bằng ngôn ngữ Python. Một Flask Web application được tạo để cho phép truy cập từ xa của mô hình Neural Network được đào tạo để phân loại hình ảnh được truyền bằng giao thức HTTP. Một trang HTML sẽ cho phép người dùng tải hình ảnh lên máy chủ (Server), có thể sử dụng JavaScript để tạo style cho Web app. Hình ảnh tải lên sẽ được phân loại bằng mô hình Neural Network được đào tạo trước đó. Output cuối cùng sẽ được hiển thị trên trang HTML mới.</p>\n",
    "\n",
    "#### 3.2 Input: <a name=\"subparagraph32\"></a>\n",
    "<p>Input sẽ là một ảnh màu của sản phẩm có kích thước 224x224x3. Tập Dataset có 200 class chứa tổng gần 54.000 ảnh và sẽ có 70% ảnh cho training, 30% ảnh cho testing. Để huấn luyện cho mô hình Neural Network, chúng tôi đọc dữ liệu từ tập dataset lưu vào mảng Data sử dụng ngôn ngữ Python, Data là một numpy array hai chiều (N,newsize x newsize), với N là số mẫu training cho model.</p>\n",
    "\n",
    "#### 3.2 Output: <a name=\"subparagraph32\"></a>\n",
    "<p>Output sẽ là nhãn được phân loại bằng mô hình Neural Network ứng với ảnh đã được tải lên máy chủ. Như chúng tôi đã đề cập từ trước, việc nhận dạng sản phẩm là một vấn đề phân loại rất khó khăn vì nhiều lớp sản phẩm giống nhau về hình dạng, màu sắc, và cùng một sản phẩm có thể được chụp từ các góc khác nhau, trong ánh sáng khác nhau, với mức độ tắc khác nhau, hơn những thế dữ liệu training cho một số sản phẩm khá ít. Điều này sẽ làm giảm hiệu suất của mô hình khá nhiều, những chúng tôi sẽ cố gắng để có thể tăng chất lượng mô hình hết sức có thể.</p>\n",
    "\n",
    "### 4. Our proposal: <a name=\"paragraph3\"></a>\n",
    "#### 4.1 Data preparation: <a name=\"subparagraph41\"></a>\n",
    "<pre></pre>\n",
    "Với tâp Dataset gồm 200 class tổng gần 54.000 mẫu, kích thước mỗi ảnh là 224x224x3, nghĩa là chiều dài ảnh = 224 pixel, chiều rộng ảnh = 224 pixel và số lượng kênh ảnh là 3 (ảnh màu). Trong giai đoạn đầu của project, do hạn chế về khả năng xử lý của CPU cũng như để thực hiện việc thử nghiệm và xây dựng Neural Network Model nhanh chóng hơn, nhóm sẽ không sử dụng toàn bộ tập training data để huấn luyện mà chỉ giới hạn số lượng nhất định, và các image sẽ được chuyển từ ảnh màu (RGB) sang ảnh xám (gray), tức là kích thước ảnh lúc này sẽ là 224x224, sau đó tiến hành resize ảnh, ảnh mới sẽ có kích thước là (newsize x newsize) . Chúng tôi viết một hàm đọc dataset bằng ngôn ngữ Python để read dữ liệu, sau đó trả về 2 mảng, một mảng là data cho training [N, newsize x newsize] mà một mảng là label [N, 1], với N là số mẫu.<br>\n",
    "<img src=\"samplesdata.png\" />\n",
    "$$Figure: \\ Samples \\ of \\ data$$\n",
    "<b>Build dataset:</b><br>\n",
    "* Input: <br>\n",
    "        dataset: tập data hình ảnh sản phẩm của 200 loại khác nhau tổng cộng gần 54.000 ảnh màu. <br>\n",
    "        arguments: dataset_dir: đường dẫn chứa tập data<br>\n",
    "                   output_dir: đường dẫn chứa kết quả (output)<br>\n",
    "                   split_ratio: <br>\n",
    "                   output_size:<br>\n",
    "* Output: file numpy array chứa các dữ liệu training data, testing data, labels for training data, labels for testing data.<br>\n",
    "\n",
    "Bằng ngôn ngữ lập trình Python, chúng tôi viết một script để build dataset, lấy dữ liệu đầu vào làm tập data gồm 200 classes với gần 54.000 images, mỗi ảnh kích thước là 224x224x3, nghĩa là chiều dài ảnh = 224 pixel, chiều rộng ảnh = 224 pixel và số lượng kênh ảnh là 3 (ảnh màu). Đầu tiên chúng tôi tạo một hàm gọi là prepare_data() với mục đích là truy cập vào dataset path, đọc dữ liệu và tiền xử lý dữ liệu sau đó trả về tập data và labels. Sử dụng thư viện os trong python để xử lý liệc load class (labels) và images (data), shuffle data rồi chia thành 2 phần train và test: <br>\n",
    "```python\n",
    "image_paths = glob.glob(os.path.join(dataset_dir, '*/*.jpg'))\n",
    "random.seed(123)\n",
    "random.shuffle(image_paths)\n",
    "train_image_paths = image_paths[:int(split_ratio*len(image_paths))]\n",
    "test_image_paths = image_paths[int(split_ratio*len(image_paths)):]\n",
    "```\n",
    "Trong mỗi phần train và test, đọc images bằng opencv in Python để tiến hành preprocessing cụ thể là resize images, rồi chuyển tên các files theo dạng \"labels_filename\" và lưu lại trong mỗi thư mục train và test:<br>\n",
    "```python\n",
    "img = cv2.imread(image_path)\n",
    "resized_img = cv2.resize(img, (output_size, output_size))\n",
    "img_name = image_path.split('/')[-2].zfill(3) + '_' + image_path.split('/')[-1]\n",
    "cv2.imwrite(os.path.join(output_dir, 'train', img_name), resized_img)\n",
    "```\n",
    "\n",
    "#### 4.2 Model Neural Network: <a name=\"subparagraph42\"></a>\n",
    "Chúng tôi sử dụng mô hình ANN Logistic Regression. Đây là mô hình ANN sử dụng Logistic Regression ở các node. Nó có bốn layer - một input layer, hai hidden layer và một output layer. Input là hình ảnh có kích thước sau khi đã resize, default sẽ là 64x64, cho nên chúng ta sẽ có 4096 units ở input layer.Số units ở hidden layer lần lượt là 400 và 200 units (không tính thêm 1 bias unit) và output layer có 200 units (ứng với 200 class). Số unit ở hidden layer có thể được thay đổi trong quá trình xây dựng Model nhằm tăng hiệu suất nhận dạng cho model.\n",
    "<img src=\"model_multi_layer.jpg\" />\n",
    "$$Figure \\ 10: ANN model.[17]$$\n",
    "Sau khi đã xây dựng script build dataset, chúng tôi viết hàm input_fn để lấy data cho model, trong lúc lấy data sẽ tiến hành processing data. Hàm input_fn sẽ truy cập vào path chứa data gồm 2 thư mục train và test đã được xây dựng ở data preparation, mỗi thư mục sẽ được xử lý riêng và cần thêm argument output_size của build dataset để reshape array.  \n",
    "```python\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    if root.split('/')[-1:][0] == 'train':\n",
    "        for file in files:\n",
    "            labels = file.split('_')[-3:][0]\n",
    "            images = os.path.join(root, file)\n",
    "            # read data\n",
    "            images = cv2.imread(images)\n",
    "            # preprocessing data, RGB to GRAY\n",
    "            img = cv2.cvtColor(images, cv2.COLOR_BGR2GRAY)/255\n",
    "            X_train.append(img)\n",
    "            y_train.append(labels)\n",
    "X_train = np.array(X_train).reshape(num_of_imgs_1,output_size*output_size)\n",
    "y_train = np.array(y_train, dtype = np.uint8).reshape(-1,1)\n",
    "```\n",
    "Khi đã có được input thì chúng tôi tiến hành xây dựng model và training sử dụng class cgọi là NeuralNet.\n",
    "Logistic Regression có activation function là hàm sigmoid:<br>\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$<br>\n",
    "Và hàm hypothesys:<br>\n",
    "$$h_{\\theta}(x) = g(\\theta^{T}x) = \\frac{1}{1 + e^{-\\theta^{T}x}}$$ <br>\n",
    "Đối với ANN với mỗi node thuộc layer khác input layer đều là một Logistic Regression ta sẽ có Cost function khi kết hợp với Regurlarization:<br>\n",
    "$$h_{\\theta} (x) \\in R^{K}$$<br>\n",
    "$$( h_{\\theta} (x) )_k = k^{th} \\space output$$<br>\n",
    "$$J(\\theta) = - \\frac{1}{m} [\\sum_{i=1}^{m} \\sum_{k=1}^{K} y_{k}^{(i)} log( h _{\\theta} (x ^{(i)}) ) _k + ( 1 - y _{k} ^{(i)} ) (1 -log( h _{\\theta} (x ^{(i)}) ) _k) ] + \\frac{\\lambda}{2m} \\sum _{ℓ=1} ^{L-1} \\sum _{i=1} ^{s _{ℓ}} \\sum _{j = 1} ^{s _{ℓ+1}} (\\theta _{ji} ^{ℓ}) ^{2}$$ <br>\n",
    "$L$: Số lượng layer (Input, Hidden & Output Layer).<br>\n",
    "$Sℓ$: Số lượng neuron của layer $ℓ$<br>\n",
    "$m$ là số lượng training example trong training set <br>\n",
    "$k$ là số lượng output hay số lượng label<br>\n",
    "Công việc của chúng ta hiện tại là tìm ra được $\\mathbf{\\theta}$ sao cho $J(\\mathbf{\\theta})$ min.Để tìm cực tiểu của $J(\\mathbf{\\theta})$ ta áp dụng thuật toán Gradient Descent:<br>\n",
    "$$\\theta _j := \\theta _j - \\alpha \\frac{\\varphi}{\\varphi_{J(\\mathbf{\\theta})}} J(\\mathbf{\\theta}) $$ \n",
    "Với $\\alpha$ là learning rate.<br>\n",
    "&theta;: parameters và J(&theta;): cost funtion<br>\n",
    "Để thực hiện được thì cần phải tính được $\\frac{\\varphi}{\\varphi_{J(\\mathbf{\\theta})}} J(\\mathbf{\\theta})$, để tính được đạo hàm này là việc tương đối khó và ta cần thự hiện một thuật toán được gọi là backpropagation để tính.<br>\n",
    "<b>Backpropagation:</b> <br>\n",
    "Cho tập training: {$(x^{(1)}, y^{(1)}),..., (x^{(m)}, y^{(m)})$} <br>\n",
    "Set $\\Delta_{ij}^{(l)}$ := 0 với tất cả (l, i, j) (do đó cuối cùng bạn có một ma trận đầy số không) <br>\n",
    "Với training example t =1 to m:<br>\n",
    "1. Set $a^{(1)}$ := $x^{(t)}$ <br>\n",
    "2. Thực hiện forward propagation để tính $a^{(l)}$ với l=2,3,…,L\n",
    "3. Dùng $y^{(t)}$, tính δ(L) = $ a^{(L)} - y^{(t)}$ <br>\n",
    "Trong đó L là tổng số layer  và $a ^ {(L)}$ là vecto đầu ra của activation units cho layer cuối cùng.<br>\n",
    "4. Tính $\\delta^{(L-1)}, \\delta^{(L-2)},\\dots,\\delta^{(2)}$ dùng: <br>\n",
    "$$\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)}).*\\ a^{(l)}\\ .*\\ (1 - a^{(l)})$$ \n",
    "$$g′(z(l))=a(l) .∗ (1−a(l))$$\n",
    "5. $\\Delta^{(l)}_{i,j} := \\Delta^{(l)}_{i,j} + a_j^{(l)} \\delta_i^{(l+1)}$ hoặc với vectorization, $\\Delta^{(l)} := \\Delta^{(l)} + \\delta^{(l+1)}(a^{(l)})^T$ <br>\n",
    "Do đó, chúng ta update ma trận $\\Delta$ mới: <br>\n",
    "Với j # 0: $$ D_{(ij)}^{(l)} := \\frac{1}{m} (\\Delta^{(l)}_{i,j} + \\Lambda \\theta_{ij}^{(l)}) $$ \n",
    "Với j = 0: $$ D_{(ij)}^{(l)}:= \\frac{1}{m} \\Delta^{(l)}_{i,j} $$ \n",
    "Ma trận capital-delta D được sử dụng như một cộng tích lũy để cộng các giá trị khi chúng ta tính toán đạo hàm riêng. Từ đó, chúng ta có được:\n",
    "$$\\frac \\partial {\\partial \\Theta_{ij}^{(l)}} J(\\Theta)$$<br>\n",
    "\n",
    "Training model với hàm scipy.optimize.minimize.<br>\n",
    "```python\n",
    "scipy.optimize.minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None,\n",
    "                        constraints=(), tol=None, callback=None, options=None)\n",
    "```\n",
    "Trong đó:<br>\n",
    "* fun: Cost function.<br>\n",
    "* x0: Theta weights<br>\n",
    "* mehtod: use method L-BFGS-B<br>\n",
    "* jac: method cho việc tính gradient vector. Set True.<br>\n",
    "* callback: Called after each iteration. <br>\n",
    "* options: use maxiter : int. Maximum number of iterations to perform.<br>\n",
    "\n",
    "Sau khi training thì model sẽ return về theta weights.<br>\n",
    "\n",
    "#### 4... Model CNN:\n",
    "Với model Neural Network chỉ cho kết quả 23%, quá nhỏ so với yêu cầu, nên chúng tôi thử ngiệm mô hình CNN với model DenseNet. \n",
    "\n",
    "#### 4.3. Evalution: <a name=\"subparagraph43\"></a>\n",
    "Để đánh giá hiệu suất của Neural Netwworks Model, ngoài hiệu suất trong quá trình training, chúng tôi đã xây dựng 1 tập test data gồm các product image không có trong tập train để test hiệu suất của model. Sau đó sẽ tiến hành cải thiện model nếu model chưa đạt yêu cầu hiêu suất mong muốn. Xây dựng hàm predict dự đoán kết quả: <br>\n",
    "```python\n",
    "def predict(Theta1,Theta2,Theta3,X):\n",
    "\"\"\"\n",
    "This function predict the label of an input given a trained neural network\n",
    "p = predict(Theta1, Theta2, Theta3, X) outputs the predicted label of X given the\n",
    "trained weights of a neural network (Theta1, Theta2)\n",
    "Arguments:\n",
    "- Theta1: array, weights between input layer and hidden layer\n",
    "- Theta2: array, weights between hidden layer 1 and hidden layer 2\n",
    "- Theta3: array, weights between hidden layer 2 and output layer\n",
    "- X: array, input data\n",
    "Return:\n",
    "- p: array, prediction\n",
    "Raises:\n",
    "- None.\n",
    "\"\"\"\n",
    "    pass\n",
    "```\n",
    "Tính hiệu suất của mô hình: Training accuracy: np.mean(p == y) * 100) <br>\n",
    "Trong đó: <br>\n",
    "* p: predict(Theta1, Theta2, Theta3, X) outputs the predicted label of X.<br>\n",
    "* y: lables.<br>\n",
    "Sử dụng confusion matrix để đánh giá kết quả:\n",
    "<img src=\"file.png\" />\n",
    "$$Figure: \\ Confusion \\ matrix.$$\n",
    "\n",
    "#### 4.4 Web application: <a name=\"subparagraph44\"></a>\n",
    "Chúng tôi sẽ thiết kế một Web application bằng framework Flask với ngôn ngữ lập trình Python và CSS - Cascading Style Sheets - để  định dạng các phần tử trên website, CSS sẽ giúp chúng ta có thể thêm một chút “phong cách” vào các phần tử HTML đó như đổi màu sắc trang, đổi màu chữ, thay đổi cấu trúc,…. Phương thức hoạt động của CSS là nó sẽ tìm dựa vào các vùng chọn, vùng chọn có thể là tên một thẻ HTML, tên một ID, class hay nhiều kiểu khác. Sau đó là nó sẽ áp dụng các thuộc tính cần thay đổi lên vùng chọn đó. Web app sẽ được tích hợp Neural Networks Model mà chúng ta đã xây dựng để thực hiện chứnc năng nhận dạng. Giao diện Home của Web-app như hình:\n",
    "<img src=\"webapp_home.png\" />\n",
    "$$Figure \\ 11:\\ Giao \\ diện \\ web \\ app.$$\n",
    "Trong đó nút \"Home\" là link giao diện chính ban đầu. \"about\" là liên kết đến bào report của chúng tôi, \"Product recognition\" là liên kết để thực hiện các bước predict product, và một số liên kết khác. Khi click vào \"Product recognition\" sẽ xuất hiện giao diện như hình:\n",
    "<img src=\"webapp_upload.png\" />\n",
    "$$Figure \\ 12:\\ Giao diện upload$$\n",
    "Khi đã chọn được hình cần predict thì click vào search để tiến hành predict. Lúc này hình ảnh sẽ được processing và read bằng opencv rồi đưa vào predict function. Kết quả sẽ là ID của sản phẩm và một số hình mẫu đi kèm với từng ID.\n",
    "<img src=\"webapp_predict.png\" />\n",
    "$$Figure \\ 13:\\ Giao diện sau khi predict$$\n",
    "\n",
    "#### 5. Our estimate: <a name=\"paragraph4\"></a>\n",
    "Dưới đây là kế hoạch về dự án của chúng tôi: \n",
    "<img src=\"table1.png\" />\n",
    "$$Table: Plan \\ of \\ the \\ project.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "<pre></pre>\n",
    "[1] Xiu-Shen Wei, Quan Cui, Lei Yang, Peng Wang, Lingqiao Liu. RPC: A Large-Scale Retail Product Checkout Dataset. <br>\n",
    "[2] Christorpher M Bishop, \"Pattern Recognition and Machine Learning\", Springer, 2006.<br>\n",
    "[3] Rafeal C.Gonzalez, Richard E.Woods, \"Digital Image Processing\", Pearson International Edition, 2000.<br>\n",
    "[4] Mark S.Nixon, Alberto S.Aguado, \"Feature Extraction and Image Processing\", Newnes, 2002.<br>\n",
    "[5] https://viblo.asia/p/tong-quan-ve-artificial-neural-network-1VgZvwYrlAw<br>\n",
    "[6] http://yann.lecun.com/exdb/mnist/<br>\n",
    "[7] Learninga Nonlinear Embedding by Preserving Class Neighbourhood Structure.<br>\n",
    "[8] Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner. Gradient-based learning applied to document recognition, 1998. <br>\n",
    "[9] Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton.Imagenet classification with deep convolutional neural networks, 2012.<br>\n",
    "[10] \"Guido van Rossum Stepping Down from Role as Python's Benevolent Dictator For Life|Linux Journal\". www.linuxjournal.com<br>\n",
    "[11] \"Python boss Guido van Rossum steps down after 30 years|TheINQUIRER\". www.theinquirer.net<br>\n",
    "[12] https://en.wikipedia.org/wiki/Guido_van_Rossum<br>\n",
    "[13] \"Pocoo Team\". Archived from the original on 2018-03-15<br>\n",
    "[14] Ronacher, Armin. \"Opening the Flask\" (PDF). Archived from the original (PDF) on 2016-12-17. Retrieved 2011-09-30.<br>\n",
    "[15] Ronacher, Armin (3 April 2010). \"April 1st Post Mortem\". Armin Ronacher's Thoughts and Writings. Archived from the original on 2018-05-14. Retrieved 2015-07-25.<br>\n",
    "[16] \"Denied: the next generation python micro-web-framework (April Fools page)\". Archived from the original on 2011-09-04. Retrieved 2011-09-30.<br>\n",
    "[17] Cousera: Machine Learning of Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
